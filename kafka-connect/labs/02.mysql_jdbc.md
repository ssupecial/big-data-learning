## MySQL JDBC Source Connector 실습

### JDBC Source Plugin 추가
- Confluent Hub 에서 JDBC Connector Plugin 다운로드
- MySQL Driver jar 파일은 포함되어있지 않기 때문에, 따로 다운로드 받아 추가
    - JDBC https://dev.mysql.com/downloads/connector/j/

### MySQL 컨테이너 실행 및 테스트 DB 생성
```sh
# MySQL 컨테이너 실행
$ docker run -d \
  --name mysql-test \
  -p 3306:3306 \
  -e MYSQL_ROOT_PASSWORD=root \
  -e MYSQL_DATABASE=testdb \
  -e MYSQL_USER=testuser \
  -e MYSQL_PASSWORD=testpass \
  mysql:8.4.0

# MySQL 컨테이너 접속
$ docker exec -it mysql-test bash

# MySQL 접속
bash-5.1# mysql -u root -p
# 비밀번호 root

# Database 생성
CREATE DATABASE om;
CREATE DATABASE stage;

# 권한 부여
-- om 데이터베이스에 대한 모든 권한 부여
GRANT ALL PRIVILEGES ON om.* TO 'testuser'@'%';

-- 권한 새로고침
FLUSH PRIVILEGES;

-- 권한 확인
SHOW GRANTS FOR 'testuser'@'%';

# 테이블 생성하는 Query문 입력
# https://github.com/chulminkw/KafkaConnect/blob/main/%EC%8B%A4%EC%8A%B5%EC%88%98%ED%96%89/MySQL%20%EC%84%A4%EC%B9%98%20%EB%B0%8F%20%ED%99%98%EA%B2%BD%20%EA%B5%AC%EC%84%B1.md
```

- Kafka Connect에서 MySQL에 접속할 수 있도록 네트워크 연결
```sh
$ docker network connect kafka-net mysql-test
```

### MySQl JDBC Source Connector Config 파일 작성
- 참고: [mysql_jdbc_om_source_00.json](../configs/mysql_jdbc_om_source_00.json)
```sh
# Connector 등록
$ http POST http://localhost:8083/connectors @mysql_jdbc_om_source_00.json
```
- 정상적으로 등록되어있는지 확인
    1. Kafka UI (localhost:8080) 접속 후 확인
    2. `$ http http://localhost:8083/connectors/mysql_jdbc_om_source_00/status`

- Kafka Connect 로그 확인
  - SELECT 문으로 데이터를 조회하는 것을 확인할 수 있다
```sh
INFO Begin using SQL query: SELECT * FROM `om`.`customers` WHERE `om`.`customers`.`customer_id` > ? ORDER BY `om`.`customers`.`customer_id` ASC (io.confluent.connect.jdbc.source.TableQuerier)
```

- `customers` 테이블에 데이터 삽입
```SQL
insert into customers values(1, 'testaddress_01@testdomain', 'testuser_01', now());
```

- 메세지 구독
```sh
$ kcat -b localhost:9094 -C -t mysql_om_customers -J -u -e | jq
```

- `incrementing` 모드 사용 시 로그
```sh
INFO Begin using SQL query: SELECT * FROM `om`.`customers` WHERE `om`.`customers`.`system_upd` > ? AND `om`.`customers`.`system_upd` < ? ORDER BY `om`.`customers`.`system_upd` ASC (io.confluent.connect.jdbc.source.TableQuerier)
```

- Notes
    - 기존 소스 커넥터 삭제 & 해당 소스커넥터가 사용하는 토픽 삭제
    - 새롭게 동일한 소스 커넥터를 생성해도, 토픽이 자동으로 생성되지 않는다.
    - connect-offsets에 이미 정보가 남아있기 때문 -> 추측, 수동으로 토픽을 만들어줘야한다.


### SMT Docs
https://docs.confluent.io/kafka-connectors/transforms/current/overview.html